\documentclass{article}
\title{Fist Tablets}
\author{James Bruska, David Joesephs, Jacob Melite, Benjamin Lannon}

\begin{document}
\maketitle
\tableofcontents

\section{Introduction}
Benjamin do this

\section{Problem Description: What is Hnefatafl}
Benjamin do this

\section{Methodology}

\subsection{Design Patterns \& Principles}
	This project uses two main design patterns in order to follow two Java coding principles. The two principles are the \textit{Liskov Substitution Principle} and the \textit{Open Closed Principle}.The Liskov Substitution Principle, in terms of Java, says that if an object has a property and another object extends it, then the child object should have all of the properties of the parent object. The Open Closed Principle can be summarized as all implementations should be open to extension and closed to modification. By following these two principles a well established program that is safe and still dynamic to change can be created. 
	The three design patterns implemented that allow this to occur are the Strategy Pattern and the Publisher Subscriber Pattern. The Strategy Pattern is a way to adapt for the Liskov Substitution Principle. With this design pattern, the programmer identifies the things that are changing within a class and then extracts them into a family of algorithms. Then composition can be used to inject this behavior back into the original object. This allows a parent class to have functions that can be modifiable in the child classes and even later at run-time. The Publisher Subscriber Pattern is implemented to help with the Open Closed Principle. This pattern loosens the connection between two objects so that they do not need to know about each other as much. One object acts as publisher and informs the program when something happens. The subscriber objects are constantly listening for a publisher to inform the program of something. When that thing happens, the listeners use the data and then make their own actions. By using these two design patterns, the two coding principles can be followed.  

\subsection{AI Algorithm}
	Before any code for the AI could be written, we had to research the optimal algorithm to use, in order to minimize the time it takes for the AI to make a move and to maximize difficulty. Initial research turned up a single paper on Hnefatafl, which stated that Hnefatafl has a branching factor of about 100, about 10 times more than chess, which has a branching factor of around 10-20. The researchers wrote that they used a neural network to create an AI, which I immediately discarded as being too complicated for this project [1]. This led us to asking Professors Sattar, Tamon, and Black for help in creating an AI. Professor Tamon pointed us to a set of algorithms called Branch-and-Bound algorithms, and lent us two books on the topic. Professor Black expanded on Professor Tamon's answer, telling us that the specific Branch-and-Bound algorithm we should use is a Minimax Search with Alpha-Beta Pruning. 
	The way the algorithm works, in a broad sense, is a Depth-First-Search that remembers the best move so far, and removes suboptimal moves while building the tree. Moves are determined to be good or bad by assigning a value to each state of the game using an evaluation function, in order to indicate how good the current board state is for either player. The evaluation function we used was based off of the one used in the paper we found. The value the function returns is as follows:
\begin{lstlisting}
	(InitialWhitePieces - RemainingWhitePieces) - (InitialBlackPieces - RemainingBlackPieces) + .1*(KingDistance)
\end{lstlisting}
The number of white captures is subtracted from the number of white captures, and the Manhattan Distance of the king to the closest corner is then weighted and added to that. The Manhattan Distance is the number of squares the king has to move in order to reach the nearest corner of the board. The evaluation function is set up so that high values are good for black, and low values are good for white. Thus, black is called the "Maximizing Player" and white is called the "Minimizing Player". The algorithm also stores two values, alpha, which represents the maximum value that the maximizing player is guaranteed to achieve, and beta, which represents the minimum value that the minimizing player is guaranteed to achieve. The program initializes alpha to negative infinity and beta to positive infinity. If beta ever drops below or becomes equal to alpha, the node that this happened on can be immediately discarded without exploring the rest of its branches, since the parent node's value will always be better than any value the current node could produce. 
	The algorithm starts by generating a list of all valid moves for the current player. A random move is selected and executed. The algorithm then recurses until either a player wins or it has looked too far ahead. We set a limit on the AI to look only 3 moves ahead, since looking 4 moves ahead increases the time required to find the best move from about half a second to ten seconds. Once the algorithm reaches either base case, the board state is evaluated, and the value that is returned is evaluated by the parent node to determine if the move is superior, equal , or inferior to other moves the parent node has made. If the move is superior, the parent node's list of children is cleared and the move is added to the list. If the move is just as good as the other moves, the move is added to the list of children. Otherwise, the move is ignored and not added to the list, to be collected by the garbage collector at a later date. Additionally, this is when alpha or beta is updated, depending on which player's turn it is. The maximizing player would update alpha, and the minimizing player would update beta. In either case, the updated value is then used to compare if beta is less than or equal to alpha. If it is, exploration is stopped and the node is immediately returned. The algorithm then undoes the move it just made, and executes another move from its list of possible moves. The function will return the current node once the list of children is empty. Once the algorithm finishes, the AI chooses a move from the root node's list of children. The list is checked to determine if a move will immediately move the king into a corner or take a piece. Any moves that satisfies either condition is returned to the player as the best move to make. If no move satisifes either condition, a move is selected at random from the list of children, since all the moves are equally good.

\section{Implementation}

\subsection{Task Allocation}
James: Game Logic
\begin{itemize}
  \item Has the most experience with android development and wants to learn other parts of Java
  \item Due to the android experience, knows how to structure the code and create the design
\end{itemize}\newline
Jacob: Artificial Intelligence
\begin{itemize}
  \item Has taken CS344, so has experience with many different algorithms and data structures
  \item Is interested in learning how an AI is created
\end{itemize}\newline
David: Graphical User Interface
\begin{itemize}
  \item 
  \item 
\end{itemize}\newline
Benjamin: Networking, Documentation, and Report management
\begin{itemize}
  \item 
  \item 
\end{itemize}\newline

\subsection{Tools}
Benjamin do this (Android Studio)

\subsection{Code Layout}

\subsubsection{GUI}
	The GUI when through many different versions. The first technique that was tried was using image buttons. The thought behind that being a move will have the piece move from one button to another by setting the image of the image button. This was quickly thrown out the window and an image view was then used for the board. At first the board was going to be a 13 by 13 board this means that that there where 169 spots on the board. The problem with this is that the space available to click on one spot on the board is very small. To combat this we decided that a 11 by 11 layout would be a better layout. This necessitated changing some of the game logic code but was revived as a good idea by all members of the group. It was also a valid change. While 13 by 13 is the more common layout there are layout that are 11 by 11 that are still valid versions of the game. 
	Now that we have settled upon a 11 by 11 board we turn our attention to the pieces themselves. There are in total 37 different pieces. 24 black pieces, 12 white pieces, and one called the King piece.  The beginning layout of the pieces are in a very easy to remember order. Besides the King piece which is called kingpiece and starts in the middle all of the pieces are named with their color first followed by their number, for example black1. The counting starts with the first square to have a piece in the upper left corner. The numbering then increases as you go across the board. When you have finish all of the pieces in one row you move down one row, go all the way to the left and continue to increment the number according to the color. This ends up with a configuration that looks like this. The middle numbers are all white and the boarder numbers are the black pieces.
        01 02 03 04 05
              06
      
07            01            08
09         02 03 04         10
11 12   05 06 Kp 07 08   13 14
15         09 10 11         16
17            12            18

              19
        20 21 22 23 24

	When you want to move a piece you have to first click on it to select it. This enables you to be able to select on anywhere on the beard to then move that piece. Where ever you touch if it is a valid place to move the piece will move to that place. This is accomplished by having a on touch command on every piece which is essentially an imageview. When a valid movement place is selected the image view is then moved to that position on the board. This was implemented using the Publisher Subscriber Pattern where each piece was a subscriber with its own listener. 

\subsubsection{Game Logic}
	The game logic is split into many parts similar to the way the real world functions. There is the board and its pieces. The player, who is in a game, makes moves following some set of rules. This layout is what the implementation tried to follow.
	Firstly, there is a \textit{Token} class. This only holds the information of each board piece such as its color and position. Then there is a \textit{Board} class. This is the board state including what tokens are on the board, their positions, and the ability change these things. Next is the \textit{Move} class which just holds the information about a move (old position, new position, and the deleted tokens). There is also a \textit{TokenMovement} class. This describes all of the legal moves that a token can make. It records the previous moves that were made and deletes the tokens that need to be. It also has the responsibility of doing an undo action. It essentially holds all of the game rules. 
	The next layer of the design is the players. There is a \textit{Player} class which establishes the basics of a player (things that all players should have). There are then two types of players, the \textit{HumanPlayer} and the \textit{ComputerPlayer}. The human player is used for the human based interaction with the game. The computer player is used for the artificial intelligence to interact with the game. There is also the \textit{PlayerInformation} class which holds all of the information about a player. This is implemented using the Strategy Pattern. It does not have any subclasses because of the way the code was developed, but it could have other information for different types of players. It was then composed within the \textit{Player} class and established within each type of player. There is also a \textit{PlayerMovement} class which can be used in then future if the project gets larger or changes. It would implemented similar to the \textit{PlayerInformation} class and would be used if different players or objects could have different allowable moves (knight and queen in chess).
	At the highest layer of the design is the game. The players are a part of the game. The is first a \textit{Game} base class. There is then the three game types that extend it: \textit{DemoGame}, \textit{LocalGame}, and \textit{SinglePlayerGame}. The different games contain their own networks and their own players. The demo game contains two computer players that fight each other over a local network. The local game has two human players that fight each other over a local connection. Finally, the single player game has a human player a computer player that both fight over a local connection. This structure of games, players, boards, and tokens allows for a complete architecture that is easy to understand and can be expanded upon easily. 

\subsubsection{AI}
	The classes used for the AI can be separated into three categories. First, there are classes which are used to hold data. Second, there are classes used to manipulate data. Lastly, there is the \textit{ComputerPlayer}, which actually executes the move suggested by the AI.  
	The \textit{PositionPair}, \textit{MovementData}, \textit{Node}, and \textit{NodeData} classes are used to store data. To pass around x,y coordinates as a pair, instead of as two separate integers, the \textit{PositionPair} class is used. To store data about where a particular \textit{Token} will move to, a \textit{Token} and a corresponding \textit{PositionPair} are stored in the \textit{MovementData} class. The \textit{Node} class uses a generic type parameter to hold any object as data, and maintains a list of children. The \textit{NodeData} class stores information about which move was made and the value of the move as evaluated by the AI's algorithm, using a \textit{MovementData} object and a \textit{double}.
	Classes used to manipulate data include the \textit{ComputerPlayerOptions} and \textit{SimpleAI} classes. The \textit{ComputerPlayerOptions} uses information from a \textit{Board} object and a \textit{TokenMovement} object to produce a list of all valid moves a particular player can make, storing the information using \textit{MovementData} objects. The \textit{SimpleAI} class ties everything together and runs the Minimax Search with Alpha Beta Pruning algorithm. It implements the \textit{ArtificialIntelligence} interface, utilizes the \textit{ComputerPlayerOptions} class through object composition, and passes around data using the \textit{PositionPair}, \textit{MovementData}, \textit{Node}, and \textit{NodeData} classes. The interface was created to allow for easy extensibility in case a different algorithm is used for the AI.
	Finally, an \textit{ArtificialIntelligence} object is used by the \textit{ComputerPlayer} class to determine what its next move should be. 

\subsubsection{Networking}
Benjamin do this
Your network uses the strategy pattern

\subsection{Testing}
	The game was incredibly difficult to debug. This is due to the fact that the game logic needed an outside input in order to test. The game's artificial intelligence also needed to the game logic to be working to run at all. Thus the game logic and artificial intelligence were intertwined. 
	The testing was done with the use of the Android Studio debugging tool. More specifically, due to the human interface of the program having errors, the game logic and artificial intelligence were tested and debugged at the same time. Two computers were put into a demo and they battled each other. There were log statements that occurred when certain actions, such as a move, took place. This allowed the debuggers to watch the game state as it changed. There were also log statements within if statements to inform the debuggers if an error occurred. The combination of all the log statements allowed for a quick assessment of what error occurred and what led to this error. 
	Later in the process, when the program was having more niche errors, a text version of the board was displayed. This was used because it was so simple that there was very little risk of having an error in the display. It allowed the overall board state to be more easily seen and analyzed.

\subsection{UML}
James do this

\section{Discussion}
**We'll all get to this**
	One of the major bugs we spent several hours debugging was causing odd behavior by the game logic, such as disappearing pieces and moves being disregarded as invalid when they should be valid. The bug arose when we had to change the x,y positions of tokens to use an 11x11 instead of a 13x13 board, but the person who modified the array positions forgot to modify the coordinates the tokens were initialized with. This had a relatively simple fix, as a few numbers in the token inititializations needed to be changed, but took hours to find, because the initialization of the board array and tokens is done in an object that is separated from the game logic. 
	A few problems arose when writing and testing the AI. First, the tree used to store all the information on what moves are being made grows big in a short amount of time. This was subverted by clearing a node's list of children when those children stored information on suboptimal moves. This solution not only cut down on storage space, but it also made deciding on which move to pick easier, as the list of children did not need to be searched to find the children with information on what the optimal moves are. Another problem that arose when testing the AI was that many moves have the same evaluation value, due to the evaluation function we chose. This meant that more than one move was being returned as the best move to make. We solved this by randomly picking any move from the list of children. However, this caused a couple other problems. A move that would kill a piece in 2 moves has the same value to the player as a move that kills a piece in 1 move, since in either case one token is captured. Similarly, moving the king into a corner after 2 moves has the same value on moving the king into a corner after 1 move. The first problem was solved by checking the list of returned moves, and picking any move that captured a token on the first turn, if there was such a move. The second problem was fixed in a similar manner, by picking a move that would move the king into a corner on the first turn, if such a move existed. The last major problem that arose with the AI was that moving the king into a corner to win was weighted less than capturing a token. This was solved by returning a big negative number for a move that moves a king into the corner, indicating that the move is really good for white and really bad for black. A very minor, but serious, bug with the AI was that the black captures and white captures were being weighted wrong. Black capturing a white piece was considered bad for black, and white capturing a black piece was considered bad for white. The fix was as simple as switching a couple negative signs around, but the bug was only caught after the game logic was fixed and we were watching games run via print line statements, perplexed at how the AI was never capturing any pieces.
	The most puzzling part of the GUI was that the movement of the pieces was taking a very long time to happen for no apparent reason. This was discovered when one of the team was working on a virtual machine. Each piece was using an image that was 960 by 960 pixels large for a game piece that was approximately 40 by 40 pixels large. When the image for the pieces was scaled down to 400 by 400 the animation became very snappy and responsive making the game much more playable than before. 
	For me this semester was the first time that I used git. I didn't even know what it was before I started using it, but when I did I liked it immediately. It solved the problem of who has the most updated code before it became a problem. 
	JAMES EXPLAIN GUI STUFF


\section{References}
[1]Hingston, Phillip. (2007). “Evolving Players for an Ancient Game: Hnefatafl.” Computational Intelligence and Games, 2007. CIG 2007. IEEE Symposium on. IEEE, 2007.
\end{document}